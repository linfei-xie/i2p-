{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 32-bit",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "c617fa10d1ba9d6a36573c3c4f7496e3bb2fbcdd4aeff3a055aadb58d26c8355"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Greater London, Greater Manchester, West Midlands\n['Greater London', 'Greater Manchester', 'West Midlands']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "myData = [\n",
    "    ['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], \n",
    "    ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], \n",
    "    ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], \n",
    "    ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']\n",
    "]\n",
    "col = myData[0].index('Name')\n",
    "cities = []\n",
    "for i in range(1,len(myData)):\n",
    "    cities.append(myData[i][col])\n",
    "print(\", \".join(cities))\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "myData = [\n",
    "    ['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], \n",
    "    ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], \n",
    "    ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], \n",
    "    ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']\n",
    "]\n",
    "col = myData[0].index('Name')\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "fruits = ['apple', 'banana', 'cherry']\n",
    "\n",
    "x = fruits.index(\"cherry\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "fruits = [4, 55, 64, 32, 16, 32]\n",
    "\n",
    "x = fruits.index(32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Greater London, Greater Manchester, Birmingham, Edinburgh, Inverness, Lerwick\n['Greater London', 'Greater Manchester', 'Birmingham', 'Edinburgh', 'Inverness', 'Lerwick']\n"
     ]
    }
   ],
   "source": [
    "myData = {\n",
    "    'id'         : [0, 1, 2, 3, 4, 5],\n",
    "    'Name'       : ['Greater London', 'Greater Manchester', 'Birmingham','Edinburgh','Inverness','Lerwick'],\n",
    "    'Rank'       : [1, 2, 3, 4, 5, 6],\n",
    "    'Longitude'  : [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145],\n",
    "    'Latitude'   : [51.507, 53.479, 52.480, 55.953, 57.478, 60.155],\n",
    "    'Population' : [9787426, 2705000, 1141816, 901455, 70000, 6958],\n",
    "}\n",
    "print(\", \".join(myData['Name']))\n",
    "print(myData['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Manchester's population is 2705000\n"
     ]
    }
   ],
   "source": [
    "city = 'Greater Manchester'\n",
    "pop = myData['Population'][ myData['Name'].index(city) ]\n",
    "print(f\"Manchester's population is {pop}\") # Notice how 'f-strings' work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The easternmost city is: Greater London\n"
     ]
    }
   ],
   "source": [
    "city = myData['Name'][ myData['Longitude'].index( max( myData['Longitude']) ) ]\n",
    "print(f\"The easternmost city is: {city}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The town of Lerwick can be found at 1.145ºW, 60.155ºN\n"
     ]
    }
   ],
   "source": [
    "city = \"Lerwick\"\n",
    "print(f\"The town of {city} can be found at \" + \n",
    "      f\"{abs(myData['Longitude'][myData['Name'].index(city)])}ºW, {myData['Latitude'][myData['Name'].index(city)]}ºN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "w=(1,2,3,4,5)\n",
    "c=np.mean(w)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The mean population is: 2435442.5\n"
     ]
    }
   ],
   "source": [
    "myData = {\n",
    "    'id'         : [0, 1, 2, 3, 4, 5],\n",
    "    'Name'       : ['Greater London', 'Greater Manchester', 'Birmingham','Edinburgh','Inverness','Lerwick'],\n",
    "    'Rank'       : [1, 2, 3, 4, 5, 6],\n",
    "    'Longitude'  : [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145],\n",
    "    'Latitude'   : [51.507, 53.479, 52.480, 55.953, 57.478, 60.155],\n",
    "    'Population' : [9787426, 2705000, 1141816, 901455, 70000, 6958],\n",
    "}\n",
    "import numpy as np\n",
    "mean = np.mean(myData['Population'])\n",
    "print(f\"The mean population is: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "City distribution has sample mean 2435442.5 and sample standard deviation of 3406947.93.\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(myData['Population'])\n",
    "std  = np.std(myData['Population'])\n",
    "print(f\"City distribution has sample mean {mean} and sample standard deviation of {std:7.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.1579383252868527, 0.0791199354729932, -0.3797024575689938, -0.45025269939207097, -0.6942995760276591, -0.7128035277711219]\n"
     ]
    }
   ],
   "source": [
    "rs = [(x - mean)/std for x in myData['Population']]\n",
    "myData['Std. Population'] = rs\n",
    "print(myData['Std. Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "City name: Greater London, Greater Manchester, Birmingham, Edinburgh, Inverness, Lerwick\nRaw population: 9787426, 2705000, 1141816, 901455, 70000, 6958\nStandardised population: 2.158, 0.079, -0.380, -0.450, -0.694, -0.713\n"
     ]
    }
   ],
   "source": [
    "print(\"City name: \" + \", \".join( myData['Name'] ))\n",
    "print(\"Raw population: \" + \", \".join( [str(x) for x in myData['Population']] ))\n",
    "print(\"Standardised population: \" + \", \".join( [f\"{x:4.3f}\" for x in myData['Std. Population']] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "901455\nThe fourth most populous city is: Edinburgh\n"
     ]
    }
   ],
   "source": [
    "myData = {\n",
    "    'id'         : [0, 1, 2, 3, 4, 5],\n",
    "    'Name'       : ['Greater London', 'Greater Manchester', 'Birmingham','Edinburgh','Inverness','Lerwick'],\n",
    "    'Rank'       : [1, 2, 3, 4, 5, 6],\n",
    "    'Longitude'  : [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145],\n",
    "    'Latitude'   : [51.507, 53.479, 52.480, 55.953, 57.478, 60.155],\n",
    "    'Population' : [9787426, 2705000, 1141816, 901455, 70000, 6958],\n",
    "}\n",
    "sorted(myData['Population'], reverse=True)\n",
    "fourth = sorted(myData['Population'], reverse=True)[3]\n",
    "print(fourth)\n",
    "idx = myData['Population'].index(fourth)\n",
    "city = myData['Name'][idx]\n",
    "print(\"The fourth most populous city is: \" + str(city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "urlData has 101 rows and 26 columns.\n['40373464', 'Modern, Small Double Private Room']\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "\n",
    "url = \"https://github.com/jreades/i2p/raw/master/data/2020-08-24-sample-listings.csv\"\n",
    "\n",
    "urlData = [] # Somewhere to store the data\n",
    "\n",
    "response = urlopen(url) # Get the data using the urlopen function\n",
    "csvfile  = csv.reader(response.read().decode('utf-8').splitlines()) # Pass it over to the reader\n",
    "\n",
    "for row in csvfile:\n",
    "    urlData.append(row)\n",
    "\n",
    "print(\"urlData has \" + str(len(urlData)) + \" rows and \" + str(len(urlData[0])) + \" columns.\")\n",
    "print(urlData[-1][:2]) # Check it worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/jreades/i2p/raw/master/data/2020-08-24-sample-listings.csv\"\n",
    "out = os.path.join('data','2020-08-24-sample-listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found data\\2020-08-24-sample-listings.csv!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def get_url(src, dest):\n",
    "    \n",
    "    # Check if dest does *not* exist -- that\n",
    "    # would mean we had to download it!\n",
    "    if not os.path.isfile(dest):\n",
    "        print(f\"{dest} not found!\")\n",
    "    else:\n",
    "        print(f\"Found {dest}!\")\n",
    "        \n",
    "get_url(url, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data\\2020-08-24-sample-listings.csv not found, downloading!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "UnicodeEncodeError",
     "evalue": "'gbk' codec can't encode character '\\xa3' in position 2404: illegal multibyte sequence",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d33cdfa9a6da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Using the `return contents` line we make it easy to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# see what our function is up to.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-d33cdfa9a6da>\u001b[0m in \u001b[0;36mget_url\u001b[1;34m(src, dest)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# but what should we write?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiledata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'gbk' codec can't encode character '\\xa3' in position 2404: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import os\n",
    "url = \"https://github.com/jreades/i2p/raw/master/data/2020-08-24-sample-listings.csv\"\n",
    "out = os.path.join('data','2020-08-24-sample-listings.csv')\n",
    "def get_url(src, dest):\n",
    "    \n",
    "    # Check if dest does *not* exist -- that\n",
    "    # would mean we had to download it!\n",
    "    if  not os.path.isfile(dest):\n",
    "        print(f\"{dest} not found, downloading!\")\n",
    "        \n",
    "        # Get the data using the urlopen function\n",
    "        response = urlopen(src) \n",
    "        filedata = response.read().decode('utf-8')\n",
    "        \n",
    "        # Extract the part of the dest(ination) that is *not*\n",
    "        # the actual filename--have a look at how \n",
    "        # os.path.split works using `help(os.path.split)`\n",
    "        path = list(os.path.split(dest)[:-1])\n",
    "        \n",
    "        # Create any missing directories in dest(ination) path\n",
    "        # -- os.path.join is the reverse of split (as you saw above)\n",
    "        # but it doesn't work with lists... so I had to google how \n",
    "        # to use the 'splat' operator! os.makedirs creates missing \n",
    "        # directories in a path automatically.\n",
    "        if len(path) >= 1 and path[0] != '':\n",
    "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
    "        \n",
    "        # This would be how to write data to a file, \n",
    "        # but what should we write?\n",
    "        with open(dest, 'w') as f:\n",
    "            f.write(filedata)\n",
    "            \n",
    "    else:\n",
    "        print(f\"Found {dest} locally!\")\n",
    "    \n",
    "    with open(dest, 'r') as f:\n",
    "        return f.read().splitlines()\n",
    "        \n",
    "# Using the `return contents` line we make it easy to \n",
    "# see what our function is up to.\n",
    "c = get_url(url, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Notice that it doesn't make sense to use `dest` as the \n",
    "# parameter name here because we always read *from* a data\n",
    "# source. Your names can be whatever you want, but they \n",
    "# should be logical wherever possible!\n",
    "def to_lol(lst):\n",
    "    \n",
    "    # Rest of code to read file and convert it goes here\n",
    "    csvdata = []\n",
    "    \n",
    "    # This is the same code that you used last week, but \n",
    "    # you'll have to rename some vars to get things to\n",
    "    # work for you here.\n",
    "    csvfile  = csv.reader(lst)\n",
    "    for row in csvfile:              \n",
    "        csvdata.append( row )\n",
    "    \n",
    "    # Return list of lists\n",
    "    return csvdata\n",
    "        \n",
    "# Save the CSV-LoL to a new variable\n",
    "clol = to_lol(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LoL has 1 rows and 1 columns.\n['data\\\\2020-08-24-sample-listings.csv']\n['data\\\\2020-08-24-sample-listings.csv']\n"
     ]
    }
   ],
   "source": [
    "print(f\"LoL has {len(clol)} rows and {len(clol[0])} columns.\")\n",
    "print(clol[0][:2])\n",
    "print(clol[-1][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}